# í•©ì„±ë°ì´í„° ê¸°ë°˜ ê°ì²´ íƒì§€ AI ê²½ì§„ëŒ€íšŒ

# ğŸ† Result
## **ìµœì¢… 1ë“±(ğŸ†)**

<img width="70%" src="https://github.com/jjuhyeok/Visol-Synthetic_Image_Object_Detection/assets/49608953/b305bb1b-c966-4a74-b98c-d01f17bc2df2"/>



<img width="100%" src="https://github.com/jjuhyeok/Visol-Synthetic_Image_Object_Detection/assets/49608953/f7849d76-3276-445d-9154-49b3c3c4e95b"/>




ì£¼ìµœ : Visol

ê·œëª¨ : 1/1500



===========================================================================
[ì†”ë£¨ì…˜ PPT Link](https://github.com/jjuhyeok/Visol-Synthetic_Image_Object_Detection/blob/main/2%EC%B0%A8%ED%8F%89%EA%B0%80_PPT/%5B%EC%A5%AC%ED%98%81%EC%9D%B4%ED%8C%80%5D%5B2%EC%B0%A8%ED%8F%89%EA%B0%80PPT%5D.pdf)  
  
    
  
---

## **ì¥¬í˜ì´ íŒ€: ìë™ì°¨ ê°ì²´ ì¸ì‹ ëŒ€íšŒ ì ‘ê·¼ë²•**

### **1. ëŒ€íšŒ ê°œìš” ë° íŒ€ ì†Œê°œ**
- **íŒ€ëª…**: ì¥¬í˜ì´ íŒ€ (Bing, ever4red, ì¤‘ìš”í•œê±´êº¾ì´ì§€ì•ŠëŠ”ë§ˆìŒ í¬í•¨)
- **ëŒ€íšŒ ê¸°ê°„**: 2023.05.08 ~ 2023.06.19
- **ëª©í‘œ**: ìë™ì°¨ ê°ì²´ë¥¼ ì¸ì‹í•˜ê³  ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œ í•´ê²°. íŠ¹íˆ **í•©ì„± ë°ì´í„°**ì™€ **ì‹¤ì œ ë°ì´í„°** ê°„ì˜ ì°¨ì´ë¥¼ ê·¹ë³µí•˜ëŠ” ê²ƒì´ í•µì‹¬ ê³¼ì œì…ë‹ˆë‹¤.

---

### **2. EDA (íƒìƒ‰ì  ë°ì´í„° ë¶„ì„)**
#### **ë„ë©”ì¸ ì§€ì‹ í™œìš© ë° ë¬¸ì œ ë°œê²¬**
- **ì‰ë³´ë ˆ ìŠ¤íŒŒí¬ ë¶„ì„**:
  - í•™ìŠµ ë°ì´í„°ì—ì„œ **2ë²ˆ í´ë˜ìŠ¤**ë¡œ ë¼ë²¨ë§ëœ ì°¨ëŸ‰ì€ ì‹¤ì œë¡œ 1ì„¸ëŒ€ ìŠ¤íŒŒí¬ì™€ ìœ ì‚¬í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ë¼ë²¨ì€ 2016~2021ë…„í˜•ìœ¼ë¡œ í‘œê¸°ë˜ì–´, **Label Miss Match** ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
- **IONIQ ë¶„ì„**:
  - í•™ìŠµ ë°ì´í„°ì—ëŠ” **IONIQ í•˜ì´ë¸Œë¦¬ë“œ 2019**ë§Œ í¬í•¨ë˜ì–´ ìˆì—ˆì§€ë§Œ, ì‹¤ì œë¡œëŠ” ë‹¤ì–‘í•œ ì—°ì‹ê³¼ ë¼ì¸ì—…(ì¼ë ‰íŠ¸ë¦­ í¬í•¨)ì´ ì¡´ì¬í•©ë‹ˆë‹¤.
- **í‹°ë³¼ë¦¬ ë¶„ì„**:
  - í•™ìŠµ ë°ì´í„°ì—ëŠ” **í‹°ë³¼ë¦¬ 2020ë…„ì‹**ë§Œ ì¡´ì¬í•˜ë©°, í‹°ë³¼ë¦¬ ì•„ë¨¸, ì—ì–´ ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

#### **t-SNE ë¶„ì„ ë° Cosine Similarity ì¸¡ì •**
- **t-SNE ê·¸ë˜í”„**:
  - ê³ ì°¨ì› íŠ¹ì§• ë°ì´í„°ë¥¼ 2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ì—¬ ì‹œê°í™”í–ˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ í´ë˜ìŠ¤ëŠ” ëª…í™•í•˜ê²Œ êµ°ì§‘ì„ í˜•ì„±í–ˆìœ¼ë‚˜, ì¼ë¶€ í´ë˜ìŠ¤ëŠ” ê²½ê³„ê°€ ëª¨í˜¸í–ˆìŠµë‹ˆë‹¤.
- **Cosine Similarity ë¶„ì„**:
  - ìœ ì‚¬í•œ í´ë˜ìŠ¤(ì˜ˆ: 10ë²ˆê³¼ 14ë²ˆ, 32ë²ˆê³¼ 33ë²ˆ)ì˜ ë†’ì€ ìœ ì‚¬ë„ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ í…ŒìŠ¤íŠ¸ì—ì„œ **ë¶„ë¥˜ ì˜¤ë¥˜ ê°€ëŠ¥ì„±**ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

---

### **3. í•©ì„± ë°ì´í„° í™œìš© ë° ì¦ê°• ê¸°ë²•**
#### **ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²•**
- **Color Jitter**:
  - Hue, Saturation, Lightness ì¡°ì •ì„ í†µí•´ ë‹¤ì–‘í•œ ìƒ‰ìƒ ë³€í™”ë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” í˜„ì‹¤ì—ì„œì˜ ë‹¤ì–‘í•œ ìƒ‰ìƒ ì¡°í•©ì„ ë°˜ì˜í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
- **Brightness & Contrast ì¡°ì •**:
  - ë‚ ì”¨, ì‹œê°„ ë“±ì˜ ì˜í–¥ì„ ë°˜ì˜í•˜ì—¬ ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´ì—ì„œì˜ ì ì‘ì„±ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤.
- **Equalize Transform**:
  - í•©ì„± ì´ë¯¸ì§€ì˜ ë‹¨ìˆœí•œ í…ìŠ¤ì²˜ ë¬¸ì œë¥¼ ë³´ì™„í•˜ê³ , ë‹¤ì–‘í•œ ì°¨ëŸ‰ì˜ ì„¸ë¶€ íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤.

#### **Mixup ë° Custom Cutout ê¸°ë²•**
- **Mixup**:
  - í´ë˜ìŠ¤ ê°„ ê²½ê³„ë¥¼ ë¶€ë“œëŸ½ê²Œ ë§Œë“¤ì–´, ëª¨ë¸ì´ íŠ¹ì • í´ë˜ìŠ¤ì— ëŒ€í•´ ê³¼ë„í•˜ê²Œ í™•ì‹ í•˜ì§€ ì•Šë„ë¡ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.
- **Custom Cutout**:
  - **Version 1**: ë¬¼ì²´ ê°„ ê°€ë ¤ì§ ë¬¸ì œë¥¼ í•´ê²°.
  - **Version 2**: ë¡œê³ ì™€ í—¤ë“œë¼ì´íŠ¸ì— ëŒ€í•œ ì§‘ì¤‘ë„ë¥¼ ì¤„ì„.
  - **Version 3**: í”„ë¡ íŠ¸ ë²”í¼, DRL, ë¼ë””ì—ì´í„° ê·¸ë¦´, í—¤ë“œë¨í”„ ë“± ë‹¤ì–‘í•œ ë¶€ìœ„ì— ì§‘ì¤‘í•˜ë„ë¡ ê°œì„ .

---

### **4. ëª¨ë¸ ê²€ì¦ ì „ëµ**
#### **Validation Set ì°¨ë³„í™”**
- í•©ì„± ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì´ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ì˜ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡, Validation Setì— **ë‹¤ì–‘í•œ Augmentation**ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.
- **Fog ì¡°ê±´ ì¶”ê°€**:
  - ì•ˆê°œ ë“±ì˜ ë‚ ì”¨ ì¡°ê±´ì„ ë°˜ì˜í•˜ì—¬, ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤.
- **Blur íš¨ê³¼ ì¶”ê°€**:
  - ì›€ì§ì„ì´ë‚˜ ì´ˆì  ë¬¸ì œë¡œ ì¸í•œ íë¦¿í•œ ì´ë¯¸ì§€ë¥¼ ë°˜ì˜í•´, í˜„ì‹¤ ì„¸ê³„ì˜ ë‹¤ì–‘í•œ ìƒí™©ì— ì ì‘í•  ìˆ˜ ìˆë„ë¡ í–ˆìŠµë‹ˆë‹¤.

---

### **5. ëª¨ë¸ ì„ ì • ë° ì‹¤í—˜ ê´€ë¦¬**
#### **Backbone ëª¨ë¸ ì„ ì •**
- ë‹¤ì–‘í•œ Backbone ëª¨ë¸ì„ ì‹¤í—˜í•œ ê²°ê³¼, **ResNeSt-200**ì´ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
- **ResNeSt**:
  - Split-Attention ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë‹¤ì–‘í•œ ì°¨ëŸ‰ ì†ì„±ì„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
  - Stochastic Depth ê¸°ë²•ìœ¼ë¡œ overfittingì„ ë°©ì§€í•˜ê³  ì¼ë°˜í™” ì„±ëŠ¥ì„ ê°•í™”í–ˆìŠµë‹ˆë‹¤.

#### **Cascade R-CNN ì‚¬ìš©**
- Cascade R-CNNì€ ê¸°ì¡´ Faster R-CNNì˜ ë‹¨ì ì„ ë³´ì™„í•˜ë©°, ë†’ì€ IoU Thresholdë¥¼ ì ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í–ˆìŠµë‹ˆë‹¤.

---

### **6. ì„±ëŠ¥ ë¶„ì„ ë° ê²°ê³¼**
#### **Grad-CAM ë¶„ì„**
- ëª¨ë¸ì´ ì£¼ë¡œ ë¡œê³ ì™€ ê·¸ë¦´ì„ ë³´ê³  ì˜ˆì¸¡í•˜ëŠ” ê²½í–¥ì´ ìˆìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
- Mixupê³¼ Custom Cutoutì„ í†µí•´ ëª¨ë¸ì´ ë‹¤ì–‘í•œ ë¶€ìœ„(í—¤ë“œë¨í”„, í¬ê·¸ë¨í”„, ë³´ë‹› ë“±)ë¥¼ ê³ ë ¤í•˜ë„ë¡ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

#### **Ablation Study ê²°ê³¼**
- ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²•ê³¼ Custom Cutout ì ìš©ìœ¼ë¡œ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.
- **mAP ê¸°ì¤€**ìœ¼ë¡œ ì•½ 3%ì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

---

### **7. ê²°ë¡  ë° í–¥í›„ ë°©í–¥**
- í•©ì„± ë°ì´í„°ì™€ ì‹¤ì œ ì´ë¯¸ì§€ ê°„ ì°¨ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì¦ê°• ê¸°ë²•ê³¼ ê²€ì¦ ì „ëµì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.
- **Cascade R-CNN**ê³¼ **ResNeSt**ì˜ ì¡°í•©ìœ¼ë¡œ ìµœê³ ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìœ¼ë©°, ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œë„ ë†’ì€ ì ì‘ë ¥ì„ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤.
- í–¥í›„ ë” ë‹¤ì–‘í•œ ì°¨ëŸ‰ê³¼ í™˜ê²½ì„ ê³ ë ¤í•œ ë°ì´í„° í™•ì¥ì´ í•„ìš”í•˜ë©°, ì´ ê²½í—˜ì´ AI ëª¨ë¸ì˜ ì‹¤ì œ ì ìš© ì‚¬ë¡€ì—ë„ ë„ì›€ì´ ë˜ê¸°ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.

---



âœï¸
## **ëŒ€íšŒ ëŠë‚€ì **
 - ê·¸ë™ì•ˆ ì •í˜• ë°ì´í„°ì—ë§Œ ê´€ì‹¬ì´ ë§ì•„ ì •í˜• ë°ì´í„° ê´€ë ¨ ëŒ€íšŒë§Œ ì°¸ì—¬í•˜ê¸° ë°”ë¹  ë¹„ì „ ëŒ€íšŒëŠ” í•˜ê³  ìˆì§€ ì•Šì•˜ë‹¤.
   í•˜ì§€ë§Œ ì´ë²ˆ ë¹„ì „ ëŒ€íšŒëŠ” ê·¸ ì „ë¶€í„° ê¾¸ì¤€íˆ í•¨ê»˜ ëŒ€íšŒ ê°™ì´ ì°¸ì—¬í•˜ì‹œëŠ” ë¶„ê»˜ì„œ ê°™ì´ ë‚˜ê°€ë³´ìê³  í•˜ì…”ì„œ ë„ì „í•´ë³´ê²Œ ë˜ì—ˆë‹¤.
   ì´ë²ˆ ëŒ€íšŒëŠ” ê°ì²´íƒì§€ ëŒ€íšŒì§€ë§Œ í•™ìŠµ ë°ì´í„°ê°€ ì¼ë°˜ì ì¸ í˜„ì‹¤ ì‚¬ì§„ì´ ì•„ë‹Œ, AI ê°€ ë§Œë“  Synthetic ë°ì´í„°ì˜€ê³ , ì˜ˆì¸¡ì€ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ì§„í–‰í•˜ëŠ” Taskì˜€ë‹¤.
   ê·¸ë ‡ê¸°ì— AIê°€ ë§Œë“  ì´ë¯¸ì§€ë¼ëŠ” íŠ¹ì„±ì„ ì´ìš©í•´ì„œ ëª¨ë¸ë§ì„ í•˜ëŠ” ê²ƒì´ í•„ìš”í•˜ì˜€ë‹¤.
   

   
===========================================================================

### í•©ì„± ë°ì´í„°ë¥¼ í™œìš©í•œ ìë™ì°¨ íƒì§€ AI ëª¨ë¸ ê°œë°œ
- í•©ì„±ë°ì´í„°ë€ ì‹¤ì œ í™˜ê²½ì—ì„œ ìˆ˜ì§‘ë˜ê±°ë‚˜ ì¸¡ì •ë˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë””ì§€í„¸ í™˜ê²½ì—ì„œ ìƒì„±ë˜ëŠ” ë°ì´í„°ì…‹ìœ¼ë¡œ,  ìµœê·¼ ë°©ëŒ€í•œ ì–‘ì§ˆì˜ ë°ì´í„°ì…‹ì´ í•„ìš”í•´ì§ì— ë”°ë¼ ê·¸ ì¤‘ìš”ì„±ì´ ëŒ€ë‘ë˜ê³  ìˆìŠµë‹ˆë‹¤.

- í•©ì„± ë°ì´í„°ëŠ” ë°ì´í„° ë¼ë²¨ë§ ì‘ì—…ì„ ìœ„í•œ 2ë°° ì´ìƒì˜ ì‹œê°„ ì ˆì•½ê³¼ 10ë°° ê°€ê¹Œìš´ ë¹„ìš©ì„ ì ˆê°í•˜ê²Œ í•˜ê³ , ìë™í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë¼ë²¨ë§ì˜ ë°ì´í„° ê·¸ë¦¬ê³  ì •í™•í•œ AI ëª¨ë¸ ê°œë°œì„ ìœ„í•œ ë°ì´í„°ì˜ ë‹¤ì–‘í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
- í•™ìŠµìš© í•©ì„±ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ `ìë™ì°¨ íƒì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” AI ëª¨ë¸`ì„ ê°œë°œí•´ì•¼ í•©ë‹ˆë‹¤.


## Project structure
```
Visol-Synthetic_Image_Object_Detection
â”œâ”€ .gitignore
â”œâ”€ archive  # implementation pytorch 
â”œâ”€ data  
â”‚  â”œâ”€ raw
â”‚  â”‚  â””â”€ raw data
â”‚  â”œâ”€ ensemble
â”‚  â”‚  â””â”€ ensemble data
â”‚  â””â”€ submission
â”œâ”€ models
â”‚  â””â”€ model file
â”œâ”€ mmdetection
â”‚  â”œâ”€ configs  
â”‚  â”‚  â”œâ”€ _base_  
â”‚  â”‚  â””â”€ visol  # model config
â”‚  â”‚      â””â”€ model config file.py
â”‚  â””â”€ mmdet
â”œâ”€ mmdetection3.x/
â”œâ”€ inference.py # Test Inference
â”œâ”€ grad_cam.py  # GradCam
â”œâ”€ ensemble.py  # weighted boxes fusion
â””â”€ README.md
```
## Getting Started
`Python 3.8.10` `mmdetection 2.x`
```
git clone https://github.com/Myungbin/Synthetic-Data-Object-Detection.git

python -m pip install --upgrade pip
python -m pip install -r requirements.txt

cd mmdetection
python .\tools\train.py .\configs\visol\{config_file.py}
python .\tools\test.py '{config_file_path}' '{model_result_path}' --format-only --out '{result_path}'
```
## Data
[Dataset Link](https://dacon.io/competitions/official/236107/data)  
The project utilizes a custom dataset for training and evaluation.
The dataset consists of labeled images with bounding box annotations for each object of interest.
The dataset is not included in this repository and needs to be prepared separately.


## Experiment
The default augmentations used were `Resize`, `Flip`, and `Normalize`.  
Faster R-CNN, EfficientDet, Swin Transformer, Libra R-CNN, and YOLO were used in the experiment. You can check the other experiments in the "finished_experiments" folder. In the end, `Cascade R-CNN` models was used.  

| Model         | Backbone | Depth | Augmentation                                      |  mAp |
|---------------|----------|-------|---------------------------------------------------|------|
| Cascade R-CNN | SwinT    | -     | Mixup, Cutout                                     | 0.89 |
| Libra R-CNN   | Resnest  | 200   | Mixup, Cutout, AutoAugment, PhotoMetricDistortion | 0.89 |
| Faster R-CNN  | ResNeXt  | 101   | Mixup                                             | 0.91 |
| Faster R-CNN  | ResNeSt  | 200   | Mixup                                             | 0.93 |
| Faster R-CNN  | ResNeSt  | 101   | Mixup, Cutout                                     | 0.95 |
| Cascade R-CNN | ResNeSt  | 200   | Mixup, Cutout, AutoAugment, PhotoMetricDistortion | 0.98 |
| ...           | ...      | ...   | ...                                               | ...  |

#### Ensemble
`Weighted-Boxes-Fusion` on the results of 8 models.

#### pretrain model
You can check the pretrained model weights [google drive](https://drive.google.com/drive/folders/1YaCBzoYmnUIbbKk2q81_x9H-RuYfxUxI?usp=sharing)  

## Result
Public mAp `0.9964`  Private mAP `0.99403`  

To reproduce the results of a public mAP of 0.9964 and a private mAP of 0.99403, follow these steps  
1. [v7.py](https://github.com/Myungbin/Synthetic-Data-Object-Detection/blob/main/mmdetection3.x/configs/visol/v7.py) must be trained and inferred using a seed of **2023** and the **NVIDIA RTX 4090** GPU. 
Additionally, this file utilizes `mmdetection 3.x`, it should be executed based on the following [document](https://mmdetection.readthedocs.io/en/latest/get_started.html).
2. In the [final folder](https://github.com/Myungbin/Synthetic-Data-Object-Detection/tree/main/mmdetection/configs/visol/final), `v3.py` must be trained and inferred using a seed of **1927851590** and the **NVIDIA RTX 3090** GPU.
3. `For all other cases` must be trained and inferred using a seed of **378452678** and the **NVIDIA A100** GPU.  
4. Finally, You must ensemble the inference results of each model using Weighted-Boxes-Fusion. 
The weights for models v1 to v8 are [0.05, 0.05, 0.05, 0.05, 0.2, 0.2, 0.2, 0.2].
 
You can find detailed information about the experimental results through the PowerPoint presentation.

## Development Environment
```
OS: Window11
CPU: Intel i9-11900K
RAM: 128GB
GPU: NVIDIA GeFocrce RTX3090 & RTX4090 & A100 & V100
```

## Host
- ì£¼ìµœ : ë¹„ì†”(VISOL)  
- ì£¼ê´€ : ë°ì´ì½˜(DACON)
- ê¸°ê°„ : 2023.05.08 ~ 2023.06.19 09:59  
[Competition Link](https://dacon.io/competitions/official/236107/overview/description)
